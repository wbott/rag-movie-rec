{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Chat-based Movie Search – Ask about movies by genre, actors, plot summaries, or reviews.\n",
    "* Smart Recommendations – Get personalized movie suggestions based on your preferences.\n",
    "* Instant Movie Info – View ratings, reviews, and summaries instantly—no manual searching required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xRit5A9KCx20"
   },
   "outputs": [],
   "source": [
    "# Importing the OpenAI library to interact with OpenAI's API services.\n",
    "import openai\n",
    "\n",
    "# Import basic libraries\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "import gradio as gr\n",
    "import requests\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List, Dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nKBjz45zDj6r"
   },
   "outputs": [],
   "source": [
    "# Try to get API key from environment\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# If not set, prompt the user\n",
    "if not api_key:\n",
    "    api_key = input(\"Please enter your OpenAI API key: \")\n",
    "\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title                 0\n",
      "IMDb Rating           0\n",
      "Year                  0\n",
      "Certificates          0\n",
      "Director              0\n",
      "Star Cast             0\n",
      "MetaScore             0\n",
      "Duration (minutes)    0\n",
      "Poster-src            0\n",
      "Genres                0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3653 entries, 0 to 3652\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Title               3653 non-null   object \n",
      " 1   IMDb Rating         3653 non-null   float64\n",
      " 2   Year                3653 non-null   int64  \n",
      " 3   Certificates        3653 non-null   object \n",
      " 4   Director            3653 non-null   object \n",
      " 5   Star Cast           3653 non-null   object \n",
      " 6   MetaScore           3653 non-null   float64\n",
      " 7   Duration (minutes)  3653 non-null   float64\n",
      " 8   Poster-src          3653 non-null   object \n",
      " 9   Genres              3653 non-null   object \n",
      "dtypes: float64(3), int64(1), object(6)\n",
      "memory usage: 285.5+ KB\n",
      "None\n",
      "Title                 3653\n",
      "IMDb Rating             55\n",
      "Year                    99\n",
      "Certificates            18\n",
      "Director              2574\n",
      "Star Cast             3219\n",
      "MetaScore               87\n",
      "Duration (minutes)     158\n",
      "Poster-src            3326\n",
      "Genres                  76\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Read data source and get summary values\n",
    "df = pd.read_csv('IMDb_Dataset_Composite_Cleaned.csv')\n",
    "\n",
    "# Check for null values in each column\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Get a summary of the DataFrame\n",
    "print(df.info())\n",
    "\n",
    "# Show unique values per column\n",
    "print(df.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "3UXD8fTl-D8X"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Year'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bill\\repos\\MovieFinder\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'Year'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# Run the script\u001b[39;00m\n\u001b[32m     48\u001b[39m output_file = \u001b[33m'\u001b[39m\u001b[33mMovie_Descriptions.csv\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[43mcreate_movie_descriptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mcreate_movie_descriptions\u001b[39m\u001b[34m(output_file)\u001b[39m\n\u001b[32m     32\u001b[39m descriptions = []\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m df.iterrows():\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     desc = \u001b[43mgenerate_description\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m     descriptions.append({\u001b[33m'\u001b[39m\u001b[33mTitle\u001b[39m\u001b[33m'\u001b[39m: row[\u001b[33m'\u001b[39m\u001b[33mTitle\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'\u001b[39m\u001b[33mDescription\u001b[39m\u001b[33m'\u001b[39m: desc})\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# Save to CSV\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mgenerate_description\u001b[39m\u001b[34m(row)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_description\u001b[39m(row):\n\u001b[32m      3\u001b[39m     title = row[\u001b[33m'\u001b[39m\u001b[33mTitle\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     year = \u001b[38;5;28mint\u001b[39m(\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mYear\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[32m      5\u001b[39m     genres = row[\u001b[33m'\u001b[39m\u001b[33mGenres\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      6\u001b[39m     director = row[\u001b[33m'\u001b[39m\u001b[33mDirector\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bill\\repos\\MovieFinder\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:1121\u001b[39m, in \u001b[36mSeries.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[key]\n\u001b[32m   1120\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[32m-> \u001b[39m\u001b[32m1121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1123\u001b[39m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[32m   1124\u001b[39m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[32m   1125\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bill\\repos\\MovieFinder\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:1237\u001b[39m, in \u001b[36mSeries._get_value\u001b[39m\u001b[34m(self, label, takeable)\u001b[39m\n\u001b[32m   1234\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[label]\n\u001b[32m   1236\u001b[39m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1237\u001b[39m loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[32m   1240\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[loc]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bill\\repos\\MovieFinder\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Year'"
     ]
    }
   ],
   "source": [
    "# Create movie description for each movie from the details provided in the dataset\n",
    "def generate_description(row):\n",
    "    title = row['Title']\n",
    "    year = int(row['Year'])\n",
    "    genres = row['Genres']\n",
    "    director = row['Director']\n",
    "    star_cast = format_star_cast(row['Star Cast'])\n",
    "    rating = row['IMDb Rating']\n",
    "    duration = int(row['Duration (minutes)'])\n",
    "    certificate = row['Certificates']\n",
    "    metascore = row['MetaScore']\n",
    "    # Description template\n",
    "    description = (\n",
    "        f\"{title} ({year}) is a {genres.lower()} film directed by {director}. \"\n",
    "        f\"Featuring {star_cast}, this movie has an IMDb rating of {rating}/10 and a MetaScore of {metascore}. \"\n",
    "        f\"With a runtime of {duration} minutes, it is\"\n",
    "        f\" rated {certificate}.\"\n",
    "    )\n",
    "    return description\n",
    "\n",
    "# Format star cast\n",
    "def format_star_cast(star_cast):\n",
    "    # Split by commas and strip whitespace\n",
    "    actors = [actor.strip() for actor in star_cast.split(',')]\n",
    "    if len(actors) > 3:\n",
    "        return \", \".join(actors[:3]) + \", and others\"\n",
    "    return \", \".join(actors)\n",
    "\n",
    "# Main function\n",
    "def create_movie_descriptions(output_file):\n",
    "    # Generate descriptions\n",
    "    descriptions = []\n",
    "    for _, row in df.iterrows():\n",
    "        desc = generate_description(row)\n",
    "        descriptions.append({'Title': row['Title'], 'Description': desc})\n",
    "\n",
    "    # Save to CSV\n",
    "    desc_df = pd.DataFrame(descriptions)\n",
    "    desc_df.to_csv(output_file, index=False)\n",
    "    print(f\"Descriptions saved to {output_file}\")\n",
    "\n",
    "    # Print first five descriptions\n",
    "    for _, row in desc_df.head(5).iterrows():\n",
    "        print(f\"\\nTitle: {row['Title']}\\nDescription: {row['Description']}\\n\")\n",
    "\n",
    "\n",
    "# Run the script\n",
    "output_file = 'Movie_Descriptions.csv'\n",
    "create_movie_descriptions(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title  \\\n",
      "0                                          Gladiator   \n",
      "1      Mission: Impossible - Dead Reckoning Part One   \n",
      "2                               Inglourious Basterds   \n",
      "3  The Lord of the Rings: The Fellowship of the Ring   \n",
      "4                                             Damsel   \n",
      "\n",
      "                                         Description  \n",
      "0  Gladiator (2000) is a action film directed by ...  \n",
      "1  Mission: Impossible - Dead Reckoning Part One ...  \n",
      "2  Inglourious Basterds (2009) is a adventure fil...  \n",
      "3  The Lord of the Rings: The Fellowship of the R...  \n",
      "4  Damsel (2024) is a action film directed by Jua...  \n",
      "Number of movies: 3653\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv('Movie_Descriptions.csv')\n",
    "\n",
    "# Inspect the first few rows\n",
    "print(df.head())\n",
    "print(f\"Number of movies: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "1tCJAI89-REL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Title  \\\n",
      "0                                      Gladiator   \n",
      "1                                      Gladiator   \n",
      "2  Mission: Impossible - Dead Reckoning Part One   \n",
      "3  Mission: Impossible - Dead Reckoning Part One   \n",
      "4                           Inglourious Basterds   \n",
      "\n",
      "                                               Chunk  \\\n",
      "0  Gladiator (2000) is a action film directed by ...   \n",
      "1      With a runtime of 155 minutes, it is rated R.   \n",
      "2  Mission: Impossible - Dead Reckoning Part One ...   \n",
      "3  of 7.7/10 and a MetaScore of 81.0. With a runt...   \n",
      "4  Inglourious Basterds (2009) is a adventure fil...   \n",
      "\n",
      "                                            Metadata  \n",
      "0                             {'Title': 'Gladiator'}  \n",
      "1                             {'Title': 'Gladiator'}  \n",
      "2  {'Title': 'Mission: Impossible - Dead Reckonin...  \n",
      "3  {'Title': 'Mission: Impossible - Dead Reckonin...  \n",
      "4                  {'Title': 'Inglourious Basterds'}  \n",
      "Total chunks: 7225\n"
     ]
    }
   ],
   "source": [
    "# Now, data is ready!\n",
    "# Its time to create your vector store\n",
    "# Perform Text Chunking\n",
    "\n",
    "# Initialize the text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200,  # Small chunk size due to short descriptions\n",
    "    chunk_overlap=20,  # Small overlap to preserve context\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "# Split descriptions into chunks and store with metadata\n",
    "chunks = []\n",
    "for _idx, row in df.iterrows():\n",
    "    split_texts = text_splitter.split_text(row['Description'])\n",
    "    for chunk in split_texts:\n",
    "        chunks.append({\n",
    "            'Title': row['Title'],\n",
    "            'Chunk': chunk,\n",
    "            'Metadata': {\n",
    "                'Title': row['Title']\n",
    "                # Add more metadata if needed, e.g., extract year, genre from Description\n",
    "            }\n",
    "        })\n",
    "\n",
    "# Convert chunks to a DataFrame\n",
    "chunks_df = pd.DataFrame(chunks)\n",
    "print(chunks_df.head())\n",
    "print(f\"Total chunks: {len(chunks_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "hUutqmZF-jf4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 226/226 [00:30<00:00,  7.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Title  \\\n",
      "0                                      Gladiator   \n",
      "1                                      Gladiator   \n",
      "2  Mission: Impossible - Dead Reckoning Part One   \n",
      "3  Mission: Impossible - Dead Reckoning Part One   \n",
      "4                           Inglourious Basterds   \n",
      "\n",
      "                                               Chunk  \\\n",
      "0  Gladiator (2000) is a action film directed by ...   \n",
      "1      With a runtime of 155 minutes, it is rated R.   \n",
      "2  Mission: Impossible - Dead Reckoning Part One ...   \n",
      "3  of 7.7/10 and a MetaScore of 81.0. With a runt...   \n",
      "4  Inglourious Basterds (2009) is a adventure fil...   \n",
      "\n",
      "                                           Embedding  \n",
      "0  [-0.05790012702345848, -0.014515863731503487, ...  \n",
      "1  [0.0352526493370533, -0.008303035981953144, -0...  \n",
      "2  [-0.10678184032440186, -0.053367096930742264, ...  \n",
      "3  [0.00942922756075859, -0.008778041228652, -0.0...  \n",
      "4  [-0.021513326093554497, -0.06901950389146805, ...  \n",
      "FAISS vector store created and saved.\n"
     ]
    }
   ],
   "source": [
    "# Create embeddings for the chunks\n",
    "# See https://python.langchain.com/docs/integrations/text_embedding/ for a list of available embedding models on LangChain\n",
    "\n",
    "# Load the embedding model\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "# or use 'all-MiniLM-L12-v2' for a larger model\n",
    "# or for higher quality (at the cost of speed), use all-mpnet-base-v2.\n",
    "\n",
    "# Generate embeddings for all chunks\n",
    "embeddings = embedding_model.encode(chunks_df['Chunk'].tolist(), show_progress_bar=True)\n",
    "\n",
    "# Add embeddings to the DataFrame\n",
    "chunks_df['Embedding'] = embeddings.tolist()\n",
    "print(chunks_df[['Title', 'Chunk', 'Embedding']].head())\n",
    "\n",
    "\n",
    "# Convert embeddings to a numpy array\n",
    "embedding_matrix = np.array(chunks_df['Embedding'].tolist(), dtype=np.float32)\n",
    "\n",
    "# Initialize FAISS index\n",
    "dimension = embedding_matrix.shape[1]  # Embedding dimension (384 for all-MiniLM-L6-v2)\n",
    "index = faiss.IndexFlatL2(dimension)  # L2 distance for similarity search\n",
    "index.add(embedding_matrix)  # Add embeddings to the index\n",
    "\n",
    "# Save the FAISS index\n",
    "faiss.write_index(index, 'movie_vector_store.index')\n",
    "\n",
    "# Save chunks and metadata for retrieval\n",
    "chunks_df[['Title', 'Chunk', 'Metadata']].to_csv('movie_chunks_metadata.csv', index=False)\n",
    "print(\"FAISS vector store created and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "sSlO9vblWGDt"
   },
   "outputs": [],
   "source": [
    "# Create a vector store using the created chunks and the embeddings model\n",
    "\n",
    "# Load the FAISS index\n",
    "index = faiss.read_index('movie_vector_store.index')\n",
    "\n",
    "# Load metadata\n",
    "chunks_df = pd.read_csv('movie_chunks_metadata.csv')\n",
    "\n",
    "# Load embedding model (must match vector store)\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Function to search the FAISS vector store\n",
    "\n",
    "\n",
    "def search_vector_store(query, k=5):\n",
    "    query_embedding = embedding_model.encode([query])[0]\n",
    "    query_embedding = np.array([query_embedding], dtype=np.float32)\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "    results = []\n",
    "    for idx in indices[0]:\n",
    "        result = chunks_df.iloc[idx]\n",
    "        # Handle Metadata as string (if saved as string in CSV)\n",
    "        metadata = eval(result['Metadata']) if isinstance(result['Metadata'], str) else result['Metadata']\n",
    "        results.append({\n",
    "            'Title': result['Title'],\n",
    "            'Chunk': result['Chunk'],\n",
    "            'Metadata': metadata\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The People's Story\n",
      "Chunk: The People's Story (2000) is a documentary film directed by Steven Scaffidi. Featuring Daniel Radcliffe, Emma Watson, Rupert Grint, this movie has an IMDb rating of 9.5/10 and a MetaScore of 66.0.\n",
      "Metadata: {'Title': \"The People's Story\"}\n",
      "--------------------------------------------------\n",
      "Title: Eva Hesse\n",
      "Chunk: Eva Hesse (2016) is a documentary film directed by Marcie Begleiter. Featuring Selma Blair, Bob Balaban, Patrick Kennedy, this movie has an IMDb rating of 7.1/10 and a MetaScore of 69.0. With a\n",
      "Metadata: {'Title': 'Eva Hesse'}\n",
      "--------------------------------------------------\n",
      "Title: The Kingmaker\n",
      "Chunk: The Kingmaker (2019) is a documentary film directed by Lauren Greenfield. Featuring Imelda Marcos, Etta Rosales, Ferdinand Marcos, this movie has an IMDb rating of 7.6/10 and a MetaScore of 76.0. With\n",
      "Metadata: {'Title': 'The Kingmaker'}\n",
      "--------------------------------------------------\n",
      "Title: Fauci\n",
      "Chunk: Fauci (2021) is a documentary film directed by John Hoffman. Featuring Bono George, W., Bush Francis, and others, this movie has an IMDb rating of 6.5/10 and a MetaScore of 70.0. With a runtime of 104\n",
      "Metadata: {'Title': 'Fauci'}\n",
      "--------------------------------------------------\n",
      "Title: Ivory Tower\n",
      "Chunk: Ivory Tower (2014) is a documentary film directed by Andrew Rossi. Featuring Elizabeth Armstrong, Richard Arum, Jamshed Bharucha, this movie has an IMDb rating of 7.0/10 and a MetaScore of 65.0. With\n",
      "Metadata: {'Title': 'Ivory Tower'}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Query the FAISS index\n",
    "query_text = \"Documentary about a famous person\"\n",
    "query_embedding = embedding_model.encode([query_text])[0]\n",
    "query_embedding = np.array([query_embedding], dtype=np.float32)\n",
    "\n",
    "# Search for top 5 similar chunks\n",
    "k = 5\n",
    "distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "# Retrieve results\n",
    "for idx in indices[0]:\n",
    "    print(f\"Title: {chunks_df.iloc[idx]['Title']}\")\n",
    "    print(f\"Chunk: {chunks_df.iloc[idx]['Chunk']}\")\n",
    "    print(f\"Metadata: {chunks_df.iloc[idx]['Metadata']}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "6dJXzILCXStu"
   },
   "outputs": [],
   "source": [
    "# Create the llm model\n",
    "\n",
    "# Initialize GPT-3.5-turbo\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature=0.7,  # Controls creativity\n",
    "    max_tokens=512,   # Max response tokens\n",
    "    openai_api_key=os.environ.get(\"OPENAI_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "RzhBYe1K_BCo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Recommend a documentary about a famous person\n",
      "Response: I recommend watching the documentary \"Fauci\" (2021) directed by John Hoffman. It focuses on the famous person, Dr. Anthony Fauci.\n"
     ]
    }
   ],
   "source": [
    "# Create the prompt template\n",
    "prompt_template = \"\"\"\n",
    "You are a movie expert. Based on the following movie descriptions, \n",
    "answer the user's query as accurately and concisely as possible. \n",
    "If the information is insufficient, say so.\n",
    "\n",
    "**Query**: {query}\n",
    "\n",
    "**Context**:\n",
    "{context}\n",
    "\n",
    "**Answer**:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "# Create the document processing chain\n",
    "def format_docs(results):\n",
    "    return \"\\n\\n\".join([f\"Title: {res['Title']}\\nDescription: {res['Chunk']}\" for res in results])\n",
    "\n",
    "# Create RAG chain\n",
    "rag_chain = (\n",
    "    {\"context\": lambda x: format_docs(search_vector_store(x['query'])), \"query\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Test the pipeline\n",
    "query = \"Recommend a documentary about a famous person\"\n",
    "response = rag_chain.invoke({\"query\": query})\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Recommend a documentary about a famous person\n",
      "Response: I recommend the documentary \"Fauci\" (2021) directed by John Hoffman, which focuses on the famous person Dr. Anthony Fauci. It has an IMDb rating of 6.5/10 and a MetaScore of 70.0.\n"
     ]
    }
   ],
   "source": [
    "# Invoke the retrieval chain to process the user's query\n",
    "def movie_recommendation(query):\n",
    "    try:\n",
    "        # Invoke the RAG chain with the user's query\n",
    "        response = rag_chain.invoke({\"query\": query})\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "    \n",
    "\n",
    "    \n",
    "# Test the pipeline\n",
    "query = \"Recommend a documentary about a famous person\"\n",
    "response = movie_recommendation(query)\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "cy7cQ7KG_kSG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the functionality using a Gradio UI (intermediate check)\n",
    "\n",
    "# Define the Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=movie_recommendation,\n",
    "    inputs=gr.Textbox(lines=2, placeholder=\"Enter your movie query (e.g., 'Recommend a documentary about a famous person')\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"Movie Recommendation Bot\",\n",
    "    description=\"Ask for movie recommendations or information based on a dataset of IMDb movies. Powered by a RAG system with FAISS and OpenAI's GPT-3.5-turbo.\"\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "k0ghQEvD_pcJ"
   },
   "outputs": [],
   "source": [
    "# Define various agents - each performing a particular task using tool decorator\n",
    "\n",
    "# MovieRetrieverAgent: Retrieves movies from FAISS vector store\n",
    "class MovieRetrieverAgent:\n",
    "    @tool\n",
    "    def retrieve_movies(query: str, top_k: int = 5) -> List[Dict]:\n",
    "        \"\"\"Retrieve movies from the FAISS vector store based on a query.\"\"\"\n",
    "        if not query.strip():\n",
    "            return {\"error\": \"Query cannot be empty\"}\n",
    "        try:\n",
    "            query_embedding = embedding_model.encode([query])[0]\n",
    "            query_embedding = np.array([query_embedding], dtype=np.float32)\n",
    "            distances, indices = index.search(query_embedding, top_k)\n",
    "            results = []\n",
    "            for idx in indices[0]:\n",
    "                result = chunks_df.iloc[idx]\n",
    "                metadata = eval(result['Metadata']) if isinstance(result['Metadata'], str) else result['Metadata']\n",
    "                results.append({\n",
    "                    \"title\": metadata.get(\"Title\"),\n",
    "                    \"description\": result['Chunk'],\n",
    "                    \"metadata\": metadata\n",
    "                })\n",
    "            return results if results else {\"error\": \"No movies found\"}\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Retrieval error: {str(e)}\"}\n",
    "\n",
    "class ExternalDataAgent:\n",
    "    @tool\n",
    "    def fetch_movie_ratings(title: str) -> Dict:\n",
    "        \"\"\"Fetch movie ratings from the OMDB API.\"\"\"\n",
    "        if not title.strip():\n",
    "            return {\"error\": \"Movie title cannot be empty\"}\n",
    "\n",
    "        # Get API key from environment variable or prompt user\n",
    "        api_key = os.environ.get(\"OMDB_API_KEY\")\n",
    "        if not api_key:\n",
    "            api_key = input(\"Please enter your OMDB API key: \")\n",
    "            if not api_key:\n",
    "                return {\"error\": \"OMDB API key is required\"}\n",
    "\n",
    "        # OMDB API endpoint\n",
    "        url = \"http://www.omdbapi.com/\"\n",
    "        params = {\n",
    "            \"t\": title, \n",
    "            \"apikey\": api_key,\n",
    "            \"plot\": \"full\",  # Full plot for more details}\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, params=params)\n",
    "            response.raise_for_status()  # Raise exception for bad status codes\n",
    "            data = response.json()\n",
    "\n",
    "            # Check if API returned a valid response\n",
    "            if data.get(\"Response\") == \"True\":\n",
    "                return {\n",
    "                    \"title\": data.get(\"Title\", title),\n",
    "                    \"imdb_rating\": data.get(\"imdbRating\", \"N/A\"),\n",
    "                    \"source\": \"OMDB API\",\n",
    "                    \"year\": data.get(\"Year\", \"N/A\"),\n",
    "                    \"metascore\": data.get(\"Metascore\", \"N/A\"), \n",
    "                    \"plot\": data.get(\"Plot\", \"N/A\"),\n",
    "                    \"actors\": data.get(\"Actors\", \"N/A\")\n",
    "                }\n",
    "            else:\n",
    "                return {\"error\": f\"Movie not found: {data.get('Error', 'Unknown error')}\"}\n",
    "\n",
    "        except requests.RequestException as e:\n",
    "            return {\"error\": f\"OMDB API request failed: {str(e)}\"}\n",
    "        except ValueError as e:\n",
    "            return {\"error\": f\"Invalid response from OMDB API: {str(e)}\"}\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Unexpected error: {str(e)}\"}\n",
    "\n",
    "\n",
    "# RecommendationAgent: Generates recommendations based on query\n",
    "class RecommendationAgent:\n",
    "    @tool\n",
    "    def recommend_movies(query: str, top_k: int = 3) -> List[Dict]:\n",
    "        \"\"\"Generate movie recommendations based on the query.\"\"\"\n",
    "        if not query.strip():\n",
    "            return {\"error\": \"Query cannot be empty\"}\n",
    "        try:\n",
    "            # Retrieve movies\n",
    "            retrieved = MovieRetrieverAgent.retrieve_movies.invoke({\"query\": query, \"top_k\": 5})\n",
    "            if \"error\" in retrieved:\n",
    "                return retrieved\n",
    "\n",
    "            # Generate recommendations\n",
    "            prompt_template = \"\"\"\n",
    "            You are a movie expert. Based on the user query: '{query}',\n",
    "            recommend {top_k} movies from the following list:\n",
    "            {movies}\n",
    "            Provide a brief reason for each recommendation.\n",
    "            \"\"\"\n",
    "            prompt = PromptTemplate.from_template(prompt_template)\n",
    "            movies_str = \"\\n\".join([f\"{m['title']}: {m['description']}\" for m in retrieved])\n",
    "            chain = prompt | llm | StrOutputParser()\n",
    "            response = chain.invoke({\n",
    "                \"query\": query,\n",
    "                \"top_k\": top_k,\n",
    "                \"movies\": movies_str\n",
    "            })\n",
    "\n",
    "            # Parse response\n",
    "            recommendations = []\n",
    "            for line in response.split(\"\\n\")[:top_k]:\n",
    "                if line.strip() and \":\" in line:\n",
    "                    title, reason = line.split(\":\", 1)\n",
    "                    recommendations.append({\"title\": title.strip(), \"reason\": reason.strip()})\n",
    "            return recommendations if recommendations else {\"error\": \"No recommendations generated\"}\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Recommendation error: {str(e)}\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "QFhn7mcf_ziw"
   },
   "outputs": [],
   "source": [
    "# Define the orchestrator logic to run the agents appropriately\n",
    "class MovieRecommendationOrchestrator:\n",
    "    def __init__(self):\n",
    "        self.retriever = MovieRetrieverAgent()\n",
    "        self.recommender = RecommendationAgent()\n",
    "        self.external_data = ExternalDataAgent()\n",
    "\n",
    "    def process_query(self, query: str, top_k: int = 3) -> Dict:\n",
    "        \"\"\"Orchestrate the recommendation process.\"\"\"\n",
    "        try:\n",
    "            #Retrieve movies\n",
    "            retrieved = self.retriever.retrieve_movies.invoke({\"query\": query, \"top_k\": 5})\n",
    "            if \"error\" in retrieved:\n",
    "                return {\"error\": retrieved[\"error\"], \"recommendations\": [], \"ratings\": []}\n",
    "\n",
    "            #Generate recommendations\n",
    "            recommendations = self.recommender.recommend_movies.invoke({\n",
    "                \"query\": query,\n",
    "                \"top_k\": top_k\n",
    "            })\n",
    "            if \"error\" in recommendations:\n",
    "                return {\"error\": recommendations[\"error\"], \"recommendations\": [], \"ratings\": []}\n",
    "            return recommendations\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Orchestration error: {str(e)}\", \"recommendations\": [], \"ratings\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "JV2FZaosAVLj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"error\": \"No recommendations generated\",\n",
      "  \"recommendations\": [],\n",
      "  \"ratings\": []\n",
      "}\n",
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a UI using Gradio\n",
    "\n",
    "import gradio as gr\n",
    "import json\n",
    "\n",
    "# Gradio UI\n",
    "def gradio_interface(query: str):\n",
    "    orchestrator = MovieRecommendationOrchestrator()\n",
    "\n",
    "    # Process query\n",
    "    result = orchestrator.process_query(query)\n",
    "\n",
    "    # Handle error case\n",
    "    if isinstance(result, dict) and \"error\" in result:\n",
    "        return f\"Error: {result['error']}\"\n",
    "\n",
    "    # Format output for recommendations\n",
    "    output = \"**Recommendations**:\\n\"\n",
    "    for rec in result:\n",
    "        output += f\"- {rec['title']}: {rec['reason']}\\n\"\n",
    "    return output\n",
    "\n",
    "# Launch Gradio UI\n",
    "def launch_ui():\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"# Movie Recommender\")\n",
    "        query = gr.Textbox(label=\"Query (e.g., 'Documentary about a famous person')\")\n",
    "        submit = gr.Button(\"Get Recommendations\")\n",
    "        output = gr.Textbox(label=\"Results\")\n",
    "        submit.click(\n",
    "            fn=gradio_interface,\n",
    "            inputs=[query],\n",
    "            outputs=output\n",
    "        )\n",
    "    demo.launch(server_name=\"127.0.0.1\", server_port=7863)\n",
    "\n",
    "# Example usage (for testing without UI)\n",
    "if __name__ == \"__main__\":\n",
    "    orchestrator = MovieRecommendationOrchestrator()\n",
    "    result = orchestrator.process_query(\"Documentary about a famous person\")\n",
    "    print(json.dumps(result, indent=2))\n",
    "    launch_ui()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
