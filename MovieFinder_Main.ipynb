{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This notebook showcases a proof of concept for a conversational movie assistant using Retrieval-Augmented Generation (RAG). The aim is to create a chatbot that understands natural language and helps users discover movies from an IMDb dataset.\n",
    "\n",
    "What This Chatbot Can Do:\n",
    "Chat-based Movie Search – Ask about movies by genre, actors, plot summaries, or reviews.\n",
    "\n",
    "Smart Recommendations – Get personalized movie suggestions based on your preferences.\n",
    "\n",
    "Instant Movie Info – View ratings, reviews, and summaries instantly—no manual searching required.\n",
    "\n",
    "The goal is to explore how AI can make movie discovery more natural, fast, and fun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xRit5A9KCx20"
   },
   "outputs": [],
   "source": [
    "# Importing the OpenAI library to interact with OpenAI's API services.\n",
    "import openai\n",
    "\n",
    "# Import basic libraries\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "import gradio as gr\n",
    "import requests\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List, Dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nKBjz45zDj6r"
   },
   "outputs": [],
   "source": [
    "# Try to get API key from environment\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# If not set, prompt the user\n",
    "if not api_key:\n",
    "    api_key = input(\"Please enter your OpenAI API key: \")\n",
    "\n",
    "openai.api_key = api_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data source and get summary values\n",
    "df = pd.read_csv('IMDb_Dataset_Composite_Cleaned.csv')\n",
    "\n",
    "# Check for null values in each column\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Get a summary of the DataFrame\n",
    "print(df.info())\n",
    "\n",
    "# Show unique values per column\n",
    "print(df.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3UXD8fTl-D8X"
   },
   "outputs": [],
   "source": [
    "# Create movie description for each movie from the details provided in the dataset\n",
    "def generate_description(row):\n",
    "    title = row['Title']\n",
    "    year = int(row['Year'])\n",
    "    genres = row['Genres']\n",
    "    director = row['Director']\n",
    "    star_cast = format_star_cast(row['Star Cast'])\n",
    "    rating = row['IMDb Rating']\n",
    "    duration = int(row['Duration (minutes)'])\n",
    "    certificate = row['Certificates']\n",
    "    metascore = row['MetaScore']\n",
    "    # Description template\n",
    "    description = (\n",
    "        f\"{title} ({year}) is a {genres.lower()} film directed by {director}. \"\n",
    "        f\"Featuring {star_cast}, this movie has an IMDb rating of {rating}/10 and a MetaScore of {metascore}. \"\n",
    "        f\"With a runtime of {duration} minutes, it is\"\n",
    "        f\" rated {certificate}.\"\n",
    "    )\n",
    "    return description\n",
    "\n",
    "# Format star cast\n",
    "def format_star_cast(star_cast):\n",
    "    # Split by commas and strip whitespace\n",
    "    actors = [actor.strip() for actor in star_cast.split(',')]\n",
    "    if len(actors) > 3:\n",
    "        return \", \".join(actors[:3]) + \", and others\"\n",
    "    return \", \".join(actors)\n",
    "\n",
    "# Main function\n",
    "def create_movie_descriptions(output_file):\n",
    "    # Generate descriptions\n",
    "    descriptions = []\n",
    "    for _, row in df.iterrows():\n",
    "        desc = generate_description(row)\n",
    "        descriptions.append({'Title': row['Title'], 'Description': desc})\n",
    "\n",
    "    # Save to CSV\n",
    "    desc_df = pd.DataFrame(descriptions)\n",
    "    desc_df.to_csv(output_file, index=False)\n",
    "    print(f\"Descriptions saved to {output_file}\")\n",
    "\n",
    "    # Print first five descriptions\n",
    "    for _, row in desc_df.head(5).iterrows():\n",
    "        print(f\"\\nTitle: {row['Title']}\\nDescription: {row['Description']}\\n\")\n",
    "\n",
    "\n",
    "# Run the script\n",
    "output_file = 'Movie_Descriptions.csv'\n",
    "create_movie_descriptions(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv('Movie_Descriptions.csv')\n",
    "\n",
    "# Inspect the first few rows\n",
    "print(df.head())\n",
    "print(f\"Number of movies: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1tCJAI89-REL"
   },
   "outputs": [],
   "source": [
    "# Now, data is ready!\n",
    "# Its time to create your vector store\n",
    "# Perform Text Chunking\n",
    "\n",
    "# Initialize the text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200,  # Small chunk size due to short descriptions\n",
    "    chunk_overlap=20,  # Small overlap to preserve context\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "# Split descriptions into chunks and store with metadata\n",
    "chunks = []\n",
    "for _idx, row in df.iterrows():\n",
    "    split_texts = text_splitter.split_text(row['Description'])\n",
    "    for chunk in split_texts:\n",
    "        chunks.append({\n",
    "            'Title': row['Title'],\n",
    "            'Chunk': chunk,\n",
    "            'Metadata': {\n",
    "                'Title': row['Title']\n",
    "                # Add more metadata if needed, e.g., extract year, genre from Description\n",
    "            }\n",
    "        })\n",
    "\n",
    "# Convert chunks to a DataFrame\n",
    "chunks_df = pd.DataFrame(chunks)\n",
    "print(chunks_df.head())\n",
    "print(f\"Total chunks: {len(chunks_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hUutqmZF-jf4"
   },
   "outputs": [],
   "source": [
    "# Create embeddings for the chunks\n",
    "# See https://python.langchain.com/docs/integrations/text_embedding/ for a list of available embedding models on LangChain\n",
    "\n",
    "# Load the embedding model\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "# or use 'all-MiniLM-L12-v2' for a larger model\n",
    "# or for higher quality (at the cost of speed), use all-mpnet-base-v2.\n",
    "\n",
    "# Generate embeddings for all chunks\n",
    "embeddings = embedding_model.encode(chunks_df['Chunk'].tolist(), show_progress_bar=True)\n",
    "\n",
    "# Add embeddings to the DataFrame\n",
    "chunks_df['Embedding'] = embeddings.tolist()\n",
    "print(chunks_df[['Title', 'Chunk', 'Embedding']].head())\n",
    "\n",
    "\n",
    "# Convert embeddings to a numpy array\n",
    "embedding_matrix = np.array(chunks_df['Embedding'].tolist(), dtype=np.float32)\n",
    "\n",
    "# Initialize FAISS index\n",
    "dimension = embedding_matrix.shape[1]  # Embedding dimension (384 for all-MiniLM-L6-v2)\n",
    "index = faiss.IndexFlatL2(dimension)  # L2 distance for similarity search\n",
    "index.add(embedding_matrix)  # Add embeddings to the index\n",
    "\n",
    "# Save the FAISS index\n",
    "faiss.write_index(index, 'movie_vector_store.index')\n",
    "\n",
    "# Save chunks and metadata for retrieval\n",
    "chunks_df[['Title', 'Chunk', 'Metadata']].to_csv('movie_chunks_metadata.csv', index=False)\n",
    "print(\"FAISS vector store created and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sSlO9vblWGDt"
   },
   "outputs": [],
   "source": [
    "# Create a vector store using the created chunks and the embeddings model\n",
    "\n",
    "# Load the FAISS index\n",
    "index = faiss.read_index('movie_vector_store.index')\n",
    "\n",
    "# Load metadata\n",
    "chunks_df = pd.read_csv('movie_chunks_metadata.csv')\n",
    "\n",
    "# Load embedding model (must match vector store)\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Function to search the FAISS vector store\n",
    "\n",
    "\n",
    "def search_vector_store(query, k=5):\n",
    "    query_embedding = embedding_model.encode([query])[0]\n",
    "    query_embedding = np.array([query_embedding], dtype=np.float32)\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "    results = []\n",
    "    for idx in indices[0]:\n",
    "        result = chunks_df.iloc[idx]\n",
    "        # Handle Metadata as string (if saved as string in CSV)\n",
    "        metadata = eval(result['Metadata']) if isinstance(result['Metadata'], str) else result['Metadata']\n",
    "        results.append({\n",
    "            'Title': result['Title'],\n",
    "            'Chunk': result['Chunk'],\n",
    "            'Metadata': metadata\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the FAISS index\n",
    "query_text = \"Documentary about a famous person\"\n",
    "query_embedding = embedding_model.encode([query_text])[0]\n",
    "query_embedding = np.array([query_embedding], dtype=np.float32)\n",
    "\n",
    "# Search for top 5 similar chunks\n",
    "k = 5\n",
    "distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "# Retrieve results\n",
    "for idx in indices[0]:\n",
    "    print(f\"Title: {chunks_df.iloc[idx]['Title']}\")\n",
    "    print(f\"Chunk: {chunks_df.iloc[idx]['Chunk']}\")\n",
    "    print(f\"Metadata: {chunks_df.iloc[idx]['Metadata']}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6dJXzILCXStu"
   },
   "outputs": [],
   "source": [
    "# Create the llm model\n",
    "\n",
    "# Initialize GPT-3.5-turbo\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature=0.7,  # Controls creativity\n",
    "    max_tokens=512,   # Max response tokens\n",
    "    openai_api_key=os.environ.get(\"OPENAI_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RzhBYe1K_BCo"
   },
   "outputs": [],
   "source": [
    "# Create the prompt template\n",
    "prompt_template = \"\"\"\n",
    "You are a movie expert. Based on the following movie descriptions, \n",
    "answer the user's query as accurately and concisely as possible. \n",
    "If the information is insufficient, say so.\n",
    "\n",
    "**Query**: {query}\n",
    "\n",
    "**Context**:\n",
    "{context}\n",
    "\n",
    "**Answer**:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "# Create the document processing chain\n",
    "def format_docs(results):\n",
    "    return \"\\n\\n\".join([f\"Title: {res['Title']}\\nDescription: {res['Chunk']}\" for res in results])\n",
    "\n",
    "# Create RAG chain\n",
    "rag_chain = (\n",
    "    {\"context\": lambda x: format_docs(search_vector_store(x['query'])), \"query\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Test the pipeline\n",
    "query = \"Recommend a documentary about a famous person\"\n",
    "response = rag_chain.invoke({\"query\": query})\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the retrieval chain to process the user's query\n",
    "def movie_recommendation(query):\n",
    "    try:\n",
    "        # Invoke the RAG chain with the user's query\n",
    "        response = rag_chain.invoke({\"query\": query})\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "    \n",
    "\n",
    "    \n",
    "# Test the pipeline\n",
    "query = \"Recommend a documentary about a famous person\"\n",
    "response = movie_recommendation(query)\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cy7cQ7KG_kSG"
   },
   "outputs": [],
   "source": [
    "# Test the functionality using a Gradio UI (intermediate check)\n",
    "\n",
    "# Define the Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=movie_recommendation,\n",
    "    inputs=gr.Textbox(lines=2, placeholder=\"Enter your movie query (e.g., 'Recommend a documentary about a famous person')\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"Movie Recommendation Bot\",\n",
    "    description=\"Ask for movie recommendations or information based on a dataset of IMDb movies. Powered by a RAG system with FAISS and OpenAI's GPT-3.5-turbo.\"\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k0ghQEvD_pcJ"
   },
   "outputs": [],
   "source": [
    "# Define various agents - each performing a particular task using tool decorator\n",
    "\n",
    "# MovieRetrieverAgent: Retrieves movies from FAISS vector store\n",
    "class MovieRetrieverAgent:\n",
    "    @tool\n",
    "    def retrieve_movies(query: str, top_k: int = 5) -> List[Dict]:\n",
    "        \"\"\"Retrieve movies from the FAISS vector store based on a query.\"\"\"\n",
    "        if not query.strip():\n",
    "            return {\"error\": \"Query cannot be empty\"}\n",
    "        try:\n",
    "            query_embedding = embedding_model.encode([query])[0]\n",
    "            query_embedding = np.array([query_embedding], dtype=np.float32)\n",
    "            distances, indices = index.search(query_embedding, top_k)\n",
    "            results = []\n",
    "            for idx in indices[0]:\n",
    "                result = chunks_df.iloc[idx]\n",
    "                metadata = eval(result['Metadata']) if isinstance(result['Metadata'], str) else result['Metadata']\n",
    "                results.append({\n",
    "                    \"title\": metadata.get(\"Title\"),\n",
    "                    \"description\": result['Chunk'],\n",
    "                    \"metadata\": metadata\n",
    "                })\n",
    "            return results if results else {\"error\": \"No movies found\"}\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Retrieval error: {str(e)}\"}\n",
    "\n",
    "class ExternalDataAgent:\n",
    "    @tool\n",
    "    def fetch_movie_ratings(title: str) -> Dict:\n",
    "        \"\"\"Fetch movie ratings from the OMDB API.\"\"\"\n",
    "        if not title.strip():\n",
    "            return {\"error\": \"Movie title cannot be empty\"}\n",
    "\n",
    "        # Get API key from environment variable or prompt user\n",
    "        api_key = os.environ.get(\"OMDB_API_KEY\")\n",
    "        if not api_key:\n",
    "            api_key = input(\"Please enter your OMDB API key: \")\n",
    "            if not api_key:\n",
    "                return {\"error\": \"OMDB API key is required\"}\n",
    "\n",
    "        # OMDB API endpoint\n",
    "        url = \"http://www.omdbapi.com/\"\n",
    "        params = {\n",
    "            \"t\": title, \n",
    "            \"apikey\": api_key,\n",
    "            \"plot\": \"full\",  # Full plot for more details}\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, params=params)\n",
    "            response.raise_for_status()  # Raise exception for bad status codes\n",
    "            data = response.json()\n",
    "\n",
    "            # Check if API returned a valid response\n",
    "            if data.get(\"Response\") == \"True\":\n",
    "                return {\n",
    "                    \"title\": data.get(\"Title\", title),\n",
    "                    \"imdb_rating\": data.get(\"imdbRating\", \"N/A\"),\n",
    "                    \"source\": \"OMDB API\",\n",
    "                    \"year\": data.get(\"Year\", \"N/A\"),\n",
    "                    \"metascore\": data.get(\"Metascore\", \"N/A\"), \n",
    "                    \"plot\": data.get(\"Plot\", \"N/A\"),\n",
    "                    \"actors\": data.get(\"Actors\", \"N/A\")\n",
    "                }\n",
    "            else:\n",
    "                return {\"error\": f\"Movie not found: {data.get('Error', 'Unknown error')}\"}\n",
    "\n",
    "        except requests.RequestException as e:\n",
    "            return {\"error\": f\"OMDB API request failed: {str(e)}\"}\n",
    "        except ValueError as e:\n",
    "            return {\"error\": f\"Invalid response from OMDB API: {str(e)}\"}\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Unexpected error: {str(e)}\"}\n",
    "\n",
    "\n",
    "# RecommendationAgent: Generates recommendations based on query\n",
    "class RecommendationAgent:\n",
    "    @tool\n",
    "    def recommend_movies(query: str, top_k: int = 3) -> List[Dict]:\n",
    "        \"\"\"Generate movie recommendations based on the query.\"\"\"\n",
    "        if not query.strip():\n",
    "            return {\"error\": \"Query cannot be empty\"}\n",
    "        try:\n",
    "            # Retrieve movies\n",
    "            retrieved = MovieRetrieverAgent.retrieve_movies.invoke({\"query\": query, \"top_k\": 5})\n",
    "            if \"error\" in retrieved:\n",
    "                return retrieved\n",
    "\n",
    "            # Generate recommendations\n",
    "            prompt_template = \"\"\"\n",
    "            You are a movie expert. Based on the user query: '{query}',\n",
    "            recommend {top_k} movies from the following list:\n",
    "            {movies}\n",
    "            Provide a brief reason for each recommendation.\n",
    "            \"\"\"\n",
    "            prompt = PromptTemplate.from_template(prompt_template)\n",
    "            movies_str = \"\\n\".join([f\"{m['title']}: {m['description']}\" for m in retrieved])\n",
    "            chain = prompt | llm | StrOutputParser()\n",
    "            response = chain.invoke({\n",
    "                \"query\": query,\n",
    "                \"top_k\": top_k,\n",
    "                \"movies\": movies_str\n",
    "            })\n",
    "\n",
    "            # Parse response\n",
    "            recommendations = []\n",
    "            for line in response.split(\"\\n\")[:top_k]:\n",
    "                if line.strip() and \":\" in line:\n",
    "                    title, reason = line.split(\":\", 1)\n",
    "                    recommendations.append({\"title\": title.strip(), \"reason\": reason.strip()})\n",
    "            return recommendations if recommendations else {\"error\": \"No recommendations generated\"}\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Recommendation error: {str(e)}\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QFhn7mcf_ziw"
   },
   "outputs": [],
   "source": [
    "# Define the orchestrator logic to run the agents appropriately\n",
    "class MovieRecommendationOrchestrator:\n",
    "    def __init__(self):\n",
    "        self.retriever = MovieRetrieverAgent()\n",
    "        self.recommender = RecommendationAgent()\n",
    "        self.external_data = ExternalDataAgent()\n",
    "\n",
    "    def process_query(self, query: str, top_k: int = 3) -> Dict:\n",
    "        \"\"\"Orchestrate the recommendation process.\"\"\"\n",
    "        try:\n",
    "            #Retrieve movies\n",
    "            retrieved = self.retriever.retrieve_movies.invoke({\"query\": query, \"top_k\": 5})\n",
    "            if \"error\" in retrieved:\n",
    "                return {\"error\": retrieved[\"error\"], \"recommendations\": [], \"ratings\": []}\n",
    "\n",
    "            #Generate recommendations\n",
    "            recommendations = self.recommender.recommend_movies.invoke({\n",
    "                \"query\": query,\n",
    "                \"top_k\": top_k\n",
    "            })\n",
    "            if \"error\" in recommendations:\n",
    "                return {\"error\": recommendations[\"error\"], \"recommendations\": [], \"ratings\": []}\n",
    "            return recommendations\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Orchestration error: {str(e)}\", \"recommendations\": [], \"ratings\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JV2FZaosAVLj"
   },
   "outputs": [],
   "source": [
    "# Create a UI using Gradio\n",
    "\n",
    "import gradio as gr\n",
    "import json\n",
    "\n",
    "# Gradio UI\n",
    "def gradio_interface(query: str):\n",
    "    orchestrator = MovieRecommendationOrchestrator()\n",
    "\n",
    "    # Process query\n",
    "    result = orchestrator.process_query(query)\n",
    "\n",
    "    # Handle error case\n",
    "    if isinstance(result, dict) and \"error\" in result:\n",
    "        return f\"Error: {result['error']}\"\n",
    "\n",
    "    # Format output for recommendations\n",
    "    output = \"**Recommendations**:\\n\"\n",
    "    for rec in result:\n",
    "        output += f\"- {rec['title']}: {rec['reason']}\\n\"\n",
    "    return output\n",
    "\n",
    "# Launch Gradio UI\n",
    "def launch_ui():\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"# Movie Recommender\")\n",
    "        query = gr.Textbox(label=\"Query (e.g., 'Documentary about a famous person')\")\n",
    "        submit = gr.Button(\"Get Recommendations\")\n",
    "        output = gr.Textbox(label=\"Results\")\n",
    "        submit.click(\n",
    "            fn=gradio_interface,\n",
    "            inputs=[query],\n",
    "            outputs=output\n",
    "        )\n",
    "    demo.launch(server_name=\"127.0.0.1\", server_port=7863)\n",
    "\n",
    "# Example usage (for testing without UI)\n",
    "if __name__ == \"__main__\":\n",
    "    orchestrator = MovieRecommendationOrchestrator()\n",
    "    result = orchestrator.process_query(\"Documentary about a famous person\")\n",
    "    print(json.dumps(result, indent=2))\n",
    "    launch_ui()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
